#!/usr/bin/env python3
import csv
import json
import os
import re
import sys
import urllib.parse
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
FIRECRAWL_DIR = ROOT / ".firecrawl" / "osm"
CAMPUS_CSV = ROOT / "scripts" / "osm_campuses.csv"


def _read_json_from_markdown(path: Path):
    text = path.read_text(encoding="utf-8", errors="ignore")
    # Look for fenced json block
    m = re.search(r"```json\s*(\[.*?\]|\{.*?\})\s*```", text, re.S)
    if m:
        return json.loads(m.group(1))
    # Fallback: find first JSON array/object
    start = text.find("[")
    end = text.rfind("]")
    if start != -1 and end != -1 and end > start:
        return json.loads(text[start:end + 1])
    start = text.find("{")
    end = text.rfind("}")
    if start != -1 and end != -1 and end > start:
        return json.loads(text[start:end + 1])
    raise ValueError(f"No JSON found in {path}")


def load_campuses():
    items = []
    with CAMPUS_CSV.open(newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            items.append({
                "slug": row["slug"].strip(),
                "name": row["name"].strip(),
                "query": row["query"].strip(),
                "radius_m": int(row["radius_m"].strip()),
            })
    return items


def stage1_generate_overpass_urls():
    FIRECRAWL_DIR.mkdir(parents=True, exist_ok=True)
    campuses = load_campuses()
    centers = {}

    for c in campuses:
        nom_file = FIRECRAWL_DIR / f"nominatim-{c['slug']}.md"
        if not nom_file.exists():
            raise SystemExit(f"Missing {nom_file}. Run firecrawl nominatim step first.")
        data = _read_json_from_markdown(nom_file)
        if not data:
            raise SystemExit(f"No nominatim results for {c['name']}")
        result = data[0]
        lat = float(result["lat"])
        lon = float(result["lon"])
        centers[c["slug"]] = {
            "name": c["name"],
            "lat": lat,
            "lon": lon,
            "radius_m": c["radius_m"],
            "display_name": result.get("display_name", "")
        }

        query = f"""[out:json][timeout:25];(
  way[\"building\"][\"name\"](around:{c['radius_m']},{lat},{lon});
  relation[\"building\"][\"name\"](around:{c['radius_m']},{lat},{lon});
  way[\"building\"][\"ref\"](around:{c['radius_m']},{lat},{lon});
  way[\"amenity\"=\"university\"](around:{c['radius_m']},{lat},{lon});
  way[\"amenity\"=\"college\"](around:{c['radius_m']},{lat},{lon});
  way[\"building\"=\"university\"](around:{c['radius_m']},{lat},{lon});
);out center tags;"""
        encoded = urllib.parse.quote(query)
        url = f"https://overpass.openstreetmap.fr/api/interpreter?data={encoded}"
        (FIRECRAWL_DIR / f"overpass-{c['slug']}.url").write_text(url, encoding="utf-8")

    (FIRECRAWL_DIR / "centers.json").write_text(json.dumps(centers, indent=2), encoding="utf-8")
    print("Generated overpass URLs and centers.json")


def stage2_build_dataset():
    campuses = load_campuses()
    rows = []

    for c in campuses:
        over_file = FIRECRAWL_DIR / f"overpass-{c['slug']}.md"
        if not over_file.exists():
            raise SystemExit(f"Missing {over_file}. Run firecrawl overpass step first.")
        data = _read_json_from_markdown(over_file)
        elements = data.get("elements", [])
        for el in elements:
            center = el.get("center")
            if not center:
                continue
            tags = el.get("tags", {})
            name = tags.get("name") or tags.get("ref") or tags.get("building")
            osm_id = el.get("id")
            if not osm_id:
                continue
            rows.append({
                "osm_id": int(osm_id),
                "name": name,
                "campus": c["name"],
                "latitude": float(center["lat"]),
                "longitude": float(center["lon"]),
                "tags": json.dumps(tags, ensure_ascii=False)
            })

    # Deduplicate by osm_id
    unique = {}
    for r in rows:
        unique[r["osm_id"]] = r
    rows = list(unique.values())
    rows.sort(key=lambda r: (r["campus"], r["name"] or ""))

    data_dir = ROOT / "data"
    data_dir.mkdir(exist_ok=True)
    csv_path = data_dir / "osm_buildings.csv"
    sql_path = ROOT / "src" / "main" / "resources" / "osm_buildings.sql"

    with csv_path.open("w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["osm_id", "name", "campus", "latitude", "longitude", "tags"])
        writer.writeheader()
        writer.writerows(rows)

    with sql_path.open("w", encoding="utf-8") as f:
        f.write("-- OSM buildings import. Generated by scripts/osm_import.sh\n")
        f.write("-- Source: OpenStreetMap contributors (ODbL)\n")
        for r in rows:
            name = (r["name"] or "").replace("'", "''")
            campus = (r["campus"] or "").replace("'", "''")
            tags = (r["tags"] or "{}").replace("'", "''")
            f.write(
                "INSERT INTO osm_building (osm_id, name, campus, latitude, longitude, tags) VALUES "
                f"({r['osm_id']}, '{name}', '{campus}', {r['latitude']}, {r['longitude']}, '{tags}');\n"
            )

    print(f"Wrote {len(rows)} buildings to {csv_path} and {sql_path}")


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: osm_pipeline.py stage1|stage2")
        sys.exit(1)
    stage = sys.argv[1]
    if stage == "stage1":
        stage1_generate_overpass_urls()
    elif stage == "stage2":
        stage2_build_dataset()
    else:
        raise SystemExit("Unknown stage")
